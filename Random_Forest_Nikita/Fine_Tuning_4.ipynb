{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306470a1",
   "metadata": {},
   "source": [
    "# Fine-tuning et Validation du Modèle Random Forest\n",
    "\n",
    "Ce notebook se concentre sur:\n",
    "1. Le chargement du modèle Random Forest entraîné précédemment\n",
    "2. L'optimisation des hyperparamètres par validation croisée (GridSearchCV)\n",
    "3. L'évaluation comparative des performances entre ensembles de validation et de test\n",
    "4. L'analyse des erreurs et l'ajustement des biais potentiels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd879d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184bbc8",
   "metadata": {},
   "source": [
    "# On charge la sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numpy_models_dir = 'numpy_models'\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(numpy_models_dir, 'train_features.pkl'), 'rb') as f:\n",
    "        train_features = pickle.load(f)\n",
    "    with open(os.path.join(numpy_models_dir, 'train_labels.pkl'), 'rb') as f:\n",
    "        train_labels = pickle.load(f)\n",
    "    with open(os.path.join(numpy_models_dir, 'val_features.pkl'), 'rb') as f:\n",
    "        val_features = pickle.load(f)\n",
    "    with open(os.path.join(numpy_models_dir, 'val_labels.pkl'), 'rb') as f:\n",
    "        val_labels = pickle.load(f)\n",
    "    \n",
    "    with open(os.path.join(numpy_models_dir, 'rf_model.pkl'), 'rb') as f:\n",
    "        base_model = pickle.load(f)\n",
    "    \n",
    "    print(f\"Données et modèle chargés avec succès depuis le dossier '{numpy_models_dir}'!\")\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(numpy_models_dir, 'performance_metrics.pkl'), 'rb') as f:\n",
    "            performance_metrics = pickle.load(f)\n",
    "        print(\"Métriques de performance également chargées!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Fichier de métriques non trouvé (facultatif).\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Fichiers de sauvegarde non trouvés dans le dossier '{numpy_models_dir}'.\")\n",
    "    print(\"Assurez-vous d'avoir exécuté le notebook précédent et vérifié le chemin.\")\n",
    "try:\n",
    "    print(\"\\nDimensions des données:\")\n",
    "    print(f\"Caractéristiques d'entraînement: {train_features.shape}\")\n",
    "    print(f\"Étiquettes d'entraînement: {train_labels.shape}\")\n",
    "    print(f\"Caractéristiques de validation: {val_features.shape}\")\n",
    "    print(f\"Étiquettes de validation: {val_labels.shape}\")\n",
    "except NameError:\n",
    "    print(\"Les données n'ont pas pu être chargées, impossible d'afficher les dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25223eef",
   "metadata": {},
   "source": [
    "# On re-évalue les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = base_model.predict(val_features)\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "precision = precision_score(val_labels, val_predictions)\n",
    "recall = recall_score(val_labels, val_predictions)\n",
    "f1 = f1_score(val_labels, val_predictions)\n",
    "\n",
    "print(\"\\nPerformances du modèle de base sur l'ensemble de validation:\")\n",
    "print(f\"Précision (accuracy): {accuracy:.4f}\")\n",
    "print(f\"Précision (precision): {precision:.4f}\")\n",
    "print(f\"Rappel (recall): {recall:.4f}\")\n",
    "print(f\"Score F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe3053",
   "metadata": {},
   "source": [
    "# On applique le fine-tuning via GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDébut du fine-tuning des hyperparamètres...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,               \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1           \n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(train_features, train_labels)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Fine-tuning terminé en {end_time - start_time:.2f} secondes\")\n",
    "print(f\"Meilleurs paramètres: {grid_search.best_params_}\")\n",
    "print(f\"Meilleure précision (validation croisée): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "with open('best_rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"Meilleur modèle sauvegardé!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3385be",
   "metadata": {},
   "source": [
    "# On re évalue la data avec le model fine-tuné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_rf_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "print(\"Modèle optimisé chargé avec succès!\")\n",
    "\n",
    "try:\n",
    "\n",
    "    with open('train_features.pkl', 'rb') as f:\n",
    "        train_features = pickle.load(f)\n",
    "    with open('train_labels.pkl', 'rb') as f:\n",
    "        train_labels = pickle.load(f)\n",
    "    with open('val_features.pkl', 'rb') as f:\n",
    "        val_features = pickle.load(f)\n",
    "    with open('val_labels.pkl', 'rb') as f:\n",
    "        val_labels = pickle.load(f)\n",
    "    print(\"Caractéristiques train/val chargées avec succès!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Caractéristiques non trouvées. Veuillez exécuter le code d'extraction.\")\n",
    "\n",
    "print(\"\\nÉvaluation sur l'ensemble d'entraînement...\")\n",
    "train_predictions = best_model.predict(train_features)\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "train_precision = precision_score(train_labels, train_predictions)\n",
    "train_recall = recall_score(train_labels, train_predictions)\n",
    "train_f1 = f1_score(train_labels, train_predictions)\n",
    "\n",
    "print(\"Évaluation sur l'ensemble de validation...\")\n",
    "val_predictions = best_model.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "val_precision = precision_score(val_labels, val_predictions)\n",
    "val_recall = recall_score(val_labels, val_predictions)\n",
    "val_f1 = f1_score(val_labels, val_predictions)\n",
    "\n",
    "print(\"Extraction et évaluation sur l'ensemble de test...\")\n",
    "test_dir = os.path.join('preprocessed_chest_xray', 'test')\n",
    "\n",
    "def load_and_extract_features(directory, max_samples=None):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_label, class_name in enumerate(['NORMAL', 'PNEUMONIA']):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        \n",
    "        image_files = [f for f in os.listdir(class_dir) \n",
    "                      if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
    "        \n",
    "        if max_samples is not None:\n",
    "            image_files = image_files[:max_samples]\n",
    "        \n",
    "        print(f\"Chargement de {len(image_files)} images {class_name}...\")\n",
    "        \n",
    "        for i, img_file in enumerate(image_files):\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                print(f\"  - {i}/{len(image_files)} images traitées...\")\n",
    "            \n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            mean_val = np.mean(img_array)\n",
    "            std_val = np.std(img_array)\n",
    "            min_val = np.min(img_array)\n",
    "            max_val = np.max(img_array)\n",
    "            median_val = np.median(img_array)\n",
    "            \n",
    "            h, w = img_array.shape\n",
    "            h_mid, w_mid = h // 2, w // 2\n",
    "            \n",
    "            q1 = img_array[:h_mid, :w_mid]\n",
    "            q1_mean, q1_std = np.mean(q1), np.std(q1)\n",
    "            \n",
    "            q2 = img_array[:h_mid, w_mid:]\n",
    "            q2_mean, q2_std = np.mean(q2), np.std(q2)\n",
    "            \n",
    "            q3 = img_array[h_mid:, :w_mid]\n",
    "            q3_mean, q3_std = np.mean(q3), np.std(q3)\n",
    "            \n",
    "            q4 = img_array[h_mid:, w_mid:]\n",
    "            q4_mean, q4_std = np.mean(q4), np.std(q4)\n",
    "            \n",
    "            img_features = [\n",
    "                mean_val, std_val, min_val, max_val, median_val,\n",
    "                q1_mean, q1_std, q2_mean, q2_std,\n",
    "                q3_mean, q3_std, q4_mean, q4_std\n",
    "            ]\n",
    "            \n",
    "            features.append(img_features)\n",
    "            labels.append(class_label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "try:\n",
    "    with open('test_features.pkl', 'rb') as f:\n",
    "        test_features = pickle.load(f)\n",
    "    with open('test_labels.pkl', 'rb') as f:\n",
    "        test_labels = pickle.load(f)\n",
    "    print(\"Caractéristiques de test chargées avec succès!\")\n",
    "except FileNotFoundError:\n",
    "\n",
    "    print(\"Extraction des caractéristiques de test...\")\n",
    "    test_features, test_labels = load_and_extract_features(test_dir)\n",
    "    \n",
    "\n",
    "    with open('test_features.pkl', 'wb') as f:\n",
    "        pickle.dump(test_features, f)\n",
    "    with open('test_labels.pkl', 'wb') as f:\n",
    "        pickle.dump(test_labels, f)\n",
    "    print(\"Caractéristiques de test extraites et sauvegardées!\")\n",
    "\n",
    "test_predictions = best_model.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions)\n",
    "test_recall = recall_score(test_labels, test_predictions)\n",
    "test_f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "print(\"\\n===== PERFORMANCES DU MODÈLE OPTIMISÉ =====\")\n",
    "\n",
    "print(\"\\nEnsemble d'entraînement:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall: {train_recall:.4f}\")\n",
    "print(f\"F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble de validation:\")\n",
    "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")\n",
    "print(f\"F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble de test:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nMatrices de confusion:\")\n",
    "print(\"Train:\")\n",
    "print(confusion_matrix(train_labels, train_predictions))\n",
    "print(\"\\nValidation:\")\n",
    "print(confusion_matrix(val_labels, val_predictions))\n",
    "print(\"\\nTest:\")\n",
    "print(confusion_matrix(test_labels, test_predictions))\n",
    "\n",
    "print(\"\\n===== ANALYSE DES ÉCARTS =====\")\n",
    "print(f\"Écart accuracy train-val: {train_accuracy - val_accuracy:.4f}\")\n",
    "print(f\"Écart accuracy train-test: {train_accuracy - test_accuracy:.4f}\")\n",
    "print(f\"Écart accuracy val-test: {val_accuracy - test_accuracy:.4f}\")\n",
    "\n",
    "feature_names = [\n",
    "    'Moyenne globale', 'Écart-type global', 'Min global', 'Max global', 'Médiane globale',\n",
    "    'Moyenne Q1', 'Écart-type Q1', 'Moyenne Q2', 'Écart-type Q2', \n",
    "    'Moyenne Q3', 'Écart-type Q3', 'Moyenne Q4', 'Écart-type Q4'\n",
    "]\n",
    "\n",
    "feature_importances = best_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances[sorted_idx])\n",
    "plt.xticks(range(len(feature_importances)), [feature_names[i] for i in sorted_idx], rotation=90)\n",
    "plt.title('Importance des caractéristiques')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 des caractéristiques les plus importantes:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}. {feature_names[sorted_idx[i]]}: {feature_importances[sorted_idx[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a192f",
   "metadata": {},
   "source": [
    "# Surapprentisage détécté, (1.00 impossible), création de contraintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a321fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n===== TEST D'UN MODÈLE AVEC MOINS DE SURAPPRENTISSAGE =====\")\n",
    "\n",
    "better_model = RandomForestClassifier(\n",
    "    n_estimators=100,     \n",
    "    max_depth=10,         \n",
    "    min_samples_leaf=5,   \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "better_model.fit(train_features, train_labels)\n",
    "\n",
    "better_train_preds = better_model.predict(train_features)\n",
    "better_train_acc = accuracy_score(train_labels, better_train_preds)\n",
    "\n",
    "better_val_preds = better_model.predict(val_features)\n",
    "better_val_acc = accuracy_score(val_labels, better_val_preds)\n",
    "\n",
    "better_test_preds = better_model.predict(test_features)\n",
    "better_test_acc = accuracy_score(test_labels, better_test_preds)\n",
    "\n",
    "print(\"\\nPerformances du modèle moins sujet au surapprentissage:\")\n",
    "print(f\"Accuracy Train: {better_train_acc:.4f}\")\n",
    "print(f\"Accuracy Validation: {better_val_acc:.4f}\")\n",
    "print(f\"Accuracy Test: {better_test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nÉcarts d'accuracy:\")\n",
    "print(f\"Train-Val: {better_train_acc - better_val_acc:.4f}\")\n",
    "print(f\"Train-Test: {better_train_acc - better_test_acc:.4f}\")\n",
    "print(f\"Val-Test: {better_val_acc - better_test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nComparaison avec le modèle optimisé par GridSearchCV:\")\n",
    "print(f\"Écart Train - Avant: 1.0000, Après: {better_train_acc:.4f}\")\n",
    "print(f\"Écart Val - Avant: 0.8068, Après: {better_val_acc:.4f}\")\n",
    "print(f\"Écart Test - Avant: 0.8236, Après: {better_test_acc:.4f}\")\n",
    "print(f\"Réduction de l'écart train-test: {(1.0000 - 0.8236) - (better_train_acc - better_test_acc):.4f}\")\n",
    "\n",
    "better_test_conf = confusion_matrix(test_labels, better_test_preds)\n",
    "print(\"\\nNouvelle matrice de confusion (test):\")\n",
    "print(better_test_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a967459",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Après avoir testé trois configurations de Random Forest pour la détection de pneumonie, nous constatons des performances similaires (environ 82% de précision) mais des comportements différents en termes de surapprentissage. Le modèle avec contraintes (profondeur limitée à 10 et minimum 5 échantillons par feuille) offre le meilleur équilibre entre performance et généralisation, avec un écart train-test réduit à 5.8% contre 17.6% pour le modèle optimisé par GridSearchCV. Cette expérience démontre l'importance de trouver un compromis entre ajustement aux données d'entraînement et capacité de généralisation, plutôt que de chercher uniquement à maximiser la précision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pneumonia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
