{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des Images Radiographiques Pulmonaires\n",
    "\n",
    "Ce notebook réalise le prétraitement des images de radiographie pulmonaire pour la détection de pneumonie:\n",
    "\n",
    "1. Nettoyage des images\n",
    "2. Normalisation et transformation\n",
    "3. Redimensionnement à une taille uniforme\n",
    "4. Conversion des images RGB en niveaux de gris\n",
    "5. Préparation des ensembles de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothèques standard\n",
    "import os                  \n",
    "# Gestion des chemins de fichiers et des opérations sur les répertoires\n",
    "\n",
    "import numpy as np         \n",
    "# Traitement de tableaux numériques et opérations mathématiques\n",
    "\n",
    "import pandas as pd        \n",
    "# Analyse et manipulation de données tabulaires\n",
    "\n",
    "from collections import Counter  \n",
    "# Comptage d'éléments et statistiques\n",
    "\n",
    "import time                \n",
    "# Mesure de temps d'exécution\n",
    "\n",
    "import shutil              \n",
    "# Opérations avancées sur les fichiers (copie, déplacement)\n",
    "\n",
    "import random              \n",
    "# Génération de nombres aléatoires et échantillonnage\n",
    "\n",
    "from PIL import Image      \n",
    "# Chargement, manipulation et enregistrement d'images\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "# Création de graphiques et visualisation de données\n",
    "\n",
    "%matplotlib inline       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des chemins et paramètres\n",
    "Définition des chemins source et destination pour les images originales et prétraitées, ainsi que la taille cible (256×256) pour le redimensionnement uniforme des radiographies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = 'chest_Xray'\n",
    "train_dir = os.path.join(base_path, 'train')\n",
    "val_dir = os.path.join(base_path, 'val')\n",
    "test_dir = os.path.join(base_path, 'test')\n",
    "\n",
    "preprocessed_base = 'preprocessed_chest_xray'\n",
    "preprocessed_train = os.path.join(preprocessed_base, 'train')\n",
    "preprocessed_val = os.path.join(preprocessed_base, 'val')\n",
    "preprocessed_test = os.path.join(preprocessed_base, 'test')\n",
    "\n",
    "TARGET_SIZE = (256, 256) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'une structure parallèle de dossiers (`preprocessed_chest_xray`) qui accueillera les versions prétraitées des images tout en conservant la même organisation que les données originales.RetryClaude can make mistakes. Please double-check responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs():\n",
    "    \"\"\"Crée les dossiers pour stocker les images prétraitées\"\"\"\n",
    "    os.makedirs(preprocessed_base, exist_ok=True)\n",
    "    os.makedirs(preprocessed_train, exist_ok=True)\n",
    "    os.makedirs(preprocessed_val, exist_ok=True)\n",
    "    os.makedirs(preprocessed_test, exist_ok=True)\n",
    "    \n",
    "    os.makedirs(os.path.join(preprocessed_train, 'NORMAL'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_train, 'PNEUMONIA'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_val, 'NORMAL'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_val, 'PNEUMONIA'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_test, 'NORMAL'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_test, 'PNEUMONIA'), exist_ok=True)\n",
    "    \n",
    "    print(\"Dossiers de destination créés avec succès.\")\n",
    "create_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b3877",
   "metadata": {},
   "source": [
    "# Redistribution et prétraitement des images\n",
    "\n",
    "Redistribution des images pour obtenir un ratio 80/10/10 (train/validation/test) tout en appliquant le prétraitement à chaque image. Cette approche corrige le déséquilibre initial (89/0.3/10.7) pour permettre une validation plus robuste du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a74e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, output_path, target_size=TARGET_SIZE):\n",
    "    \"\"\"\n",
    "    Prétraite une image radiographique pour l'apprentissage automatique\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if img.mode == 'RGB':\n",
    "            img = img.convert('L')\n",
    "        \n",
    "        img = img.resize(target_size, Image.LANCZOS)\n",
    "        \n",
    "\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "\n",
    "        img_array = img_array / 255.0\n",
    "        \n",
    "        normalized_img = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "        \n",
    "\n",
    "        normalized_img.save(output_path)\n",
    "    \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du prétraitement de {img_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af1d2f",
   "metadata": {},
   "source": [
    "# Application du prétraitement à toutes les images\n",
    "\n",
    "Parcours de l'ensemble du dataset (train, val, test) pour appliquer la fonction de prétraitement à chaque image et sauvegarder les versions transformées dans les dossiers correspondants. Ce processus préserve l'organisation des données tout en standardisant les caractéristiques des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba92a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_balanced_dataset():\n",
    "    \"\"\"\n",
    "    Crée un dataset parfaitement équilibré 50/50 tout en conservant TOUTES les images originales\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(preprocessed_base):\n",
    "        print(f\"Suppression du dossier {preprocessed_base} existant...\")\n",
    "        shutil.rmtree(preprocessed_base)\n",
    "        print(\"Dossier supprimé avec succès.\")\n",
    "    \n",
    "    \n",
    "    os.makedirs(preprocessed_base, exist_ok=True)\n",
    "    os.makedirs(preprocessed_train, exist_ok=True)\n",
    "    os.makedirs(preprocessed_val, exist_ok=True)\n",
    "    os.makedirs(preprocessed_test, exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_train, 'NORMAL'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_train, 'PNEUMONIA'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_val, 'NORMAL'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_val, 'PNEUMONIA'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_test, 'NORMAL'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(preprocessed_test, 'PNEUMONIA'), exist_ok=True)\n",
    "    print(\"Dossiers recréés avec succès.\")\n",
    "    \n",
    "    \n",
    "    total_processed = 0\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(\"Création d'un dataset optimisé avec équilibre 50/50...\")\n",
    "    \n",
    "    \n",
    "    normal_files = []\n",
    "    pneumonia_files = []\n",
    "    \n",
    "    for folder in ['train', 'val', 'test']:\n",
    "        \n",
    "        normal_path = os.path.join(base_path, folder, 'NORMAL')\n",
    "        if os.path.exists(normal_path):\n",
    "            for f in os.listdir(normal_path):\n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(normal_path, f)\n",
    "                    if os.path.exists(img_path):\n",
    "                        normal_files.append(img_path)\n",
    "        \n",
    "        \n",
    "        pneumonia_path = os.path.join(base_path, folder, 'PNEUMONIA')\n",
    "        if os.path.exists(pneumonia_path):\n",
    "            for f in os.listdir(pneumonia_path):\n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(pneumonia_path, f)\n",
    "                    if os.path.exists(img_path):\n",
    "                        pneumonia_files.append(img_path)\n",
    "    \n",
    "    \n",
    "    random.shuffle(normal_files)\n",
    "    random.shuffle(pneumonia_files)\n",
    "    \n",
    "    print(f\"Total images NORMAL trouvées: {len(normal_files)}\")\n",
    "    print(f\"Total images PNEUMONIA trouvées: {len(pneumonia_files)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    pneumonia_train_size = int(len(pneumonia_files) * 0.8)\n",
    "    pneumonia_val_size = int(len(pneumonia_files) * 0.1)\n",
    "    pneumonia_test_size = len(pneumonia_files) - pneumonia_train_size - pneumonia_val_size\n",
    "    \n",
    "    pneumonia_train = pneumonia_files[:pneumonia_train_size]\n",
    "    pneumonia_val = pneumonia_files[pneumonia_train_size:pneumonia_train_size+pneumonia_val_size]\n",
    "    pneumonia_test = pneumonia_files[pneumonia_train_size+pneumonia_val_size:]\n",
    "    \n",
    "    \n",
    "    normal_train_size = int(len(normal_files) * 0.8)\n",
    "    normal_val_size = int(len(normal_files) * 0.1)\n",
    "    normal_test_size = len(normal_files) - normal_train_size - normal_val_size\n",
    "    \n",
    "    normal_train = normal_files[:normal_train_size]\n",
    "    normal_val = normal_files[normal_train_size:normal_train_size+normal_val_size]\n",
    "    normal_test = normal_files[normal_train_size+normal_val_size:]\n",
    "    \n",
    "    print(f\"\\nDistribution originale divisée:\")\n",
    "    print(f\"Train: {len(normal_train)} normales, {len(pneumonia_train)} pneumonies\")\n",
    "    print(f\"Validation: {len(normal_val)} normales, {len(pneumonia_val)} pneumonies\")\n",
    "    print(f\"Test: {len(normal_test)} normales, {len(pneumonia_test)} pneumonies\")\n",
    "    \n",
    "    \n",
    "    train_aug_needed = len(pneumonia_train) - len(normal_train)\n",
    "    val_aug_needed = len(pneumonia_val) - len(normal_val)\n",
    "    test_aug_needed = len(pneumonia_test) - len(normal_test)\n",
    "    \n",
    "    print(f\"\\nAugmentations nécessaires:\")\n",
    "    print(f\"Train: {train_aug_needed} images normales supplémentaires\")\n",
    "    print(f\"Validation: {val_aug_needed} images normales supplémentaires\")\n",
    "    print(f\"Test: {test_aug_needed} images normales supplémentaires\")\n",
    "    \n",
    "    \n",
    "    def augment_dataset(source_images, dest_folder, count_needed):\n",
    "        \"\"\"Augmente un ensemble d'images pour atteindre le nombre souhaité\"\"\"\n",
    "        nonlocal total_processed, successful, failed\n",
    "        \n",
    "        aug_count = 0\n",
    "        aug_types = ['flip', 'rotate10', 'rotate-10', 'zoom', 'shift', 'brightness']\n",
    "        \n",
    "        print(f\"Génération de {count_needed} images augmentées pour {dest_folder}...\")\n",
    "        \n",
    "        \n",
    "        aug_per_image = (count_needed // len(source_images)) + 1\n",
    "        \n",
    "        for src_path in source_images:\n",
    "            if aug_count >= count_needed:\n",
    "                break\n",
    "                \n",
    "            for aug_id in range(aug_per_image):\n",
    "                if aug_count >= count_needed:\n",
    "                    break\n",
    "                    \n",
    "                aug_type = aug_types[aug_id % len(aug_types)]\n",
    "                filename = os.path.basename(src_path)\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                aug_filename = f\"{name}_aug{aug_id}{ext}\"\n",
    "                dst_path = os.path.join(dest_folder, 'NORMAL', aug_filename)\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    img = Image.open(src_path)\n",
    "                    \n",
    "                    \n",
    "                    if img.mode == 'RGB':\n",
    "                        img = img.convert('L')\n",
    "                    \n",
    "                    \n",
    "                    if aug_type == 'flip':\n",
    "                        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    elif aug_type == 'rotate10':\n",
    "                        img = img.rotate(10, resample=Image.BICUBIC, expand=False)\n",
    "                    elif aug_type == 'rotate-10':\n",
    "                        img = img.rotate(-10, resample=Image.BICUBIC, expand=False)\n",
    "                    elif aug_type == 'zoom':\n",
    "                        width, height = img.size\n",
    "                        crop_width = int(width * 0.9)\n",
    "                        crop_height = int(height * 0.9)\n",
    "                        left = (width - crop_width) // 2\n",
    "                        top = (height - crop_height) // 2\n",
    "                        img = img.crop((left, top, left + crop_width, top + crop_height))\n",
    "                        img = img.resize((width, height), Image.LANCZOS)\n",
    "                    elif aug_type == 'shift':\n",
    "                        width, height = img.size\n",
    "                        shift = int(width * 0.1)\n",
    "                        img = img.crop((shift, 0, width, height))\n",
    "                        img = img.resize((width, height), Image.LANCZOS)\n",
    "                    elif aug_type == 'brightness':\n",
    "                        img_array = np.array(img)\n",
    "                        factor = 0.8 + random.random() * 0.4  \n",
    "                        img_array = np.clip(img_array * factor, 0, 255)\n",
    "                        img = Image.fromarray(img_array.astype(np.uint8))\n",
    "                    \n",
    "                    \n",
    "                    img = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
    "                    \n",
    "                    \n",
    "                    img_array = np.array(img)\n",
    "                    img_array = img_array / 255.0\n",
    "                    normalized_img = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "                    \n",
    "                    \n",
    "                    normalized_img.save(dst_path)\n",
    "                    \n",
    "                    aug_count += 1\n",
    "                    total_processed += 1\n",
    "                    successful += 1\n",
    "                    \n",
    "                    \n",
    "                    if aug_count % 100 == 0:\n",
    "                        print(f\"  - {aug_count}/{count_needed} augmentations générées...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de l'augmentation de {src_path}: {e}\")\n",
    "                    total_processed += 1\n",
    "                    failed += 1\n",
    "        \n",
    "        return aug_count\n",
    "    \n",
    "    \n",
    "    def process_original_images(src_images, dest_folder, class_name):\n",
    "        nonlocal total_processed, successful, failed\n",
    "        \n",
    "        print(f\"Traitement de {len(src_images)} images {class_name} pour {dest_folder}...\")\n",
    "        \n",
    "        for i, src_path in enumerate(src_images):\n",
    "            filename = os.path.basename(src_path)\n",
    "            dst_path = os.path.join(dest_folder, class_name, filename)\n",
    "            \n",
    "            \n",
    "            if i > 0 and i % 100 == 0:\n",
    "                print(f\"  - {i}/{len(src_images)} images traitées...\")\n",
    "            \n",
    "            \n",
    "            total_processed += 1\n",
    "            if preprocess_image(src_path, dst_path):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "    \n",
    "    \n",
    "    process_original_images(normal_train, preprocessed_train, 'NORMAL')\n",
    "    process_original_images(pneumonia_train, preprocessed_train, 'PNEUMONIA')\n",
    "    process_original_images(normal_val, preprocessed_val, 'NORMAL')\n",
    "    process_original_images(pneumonia_val, preprocessed_val, 'PNEUMONIA')\n",
    "    process_original_images(normal_test, preprocessed_test, 'NORMAL')\n",
    "    process_original_images(pneumonia_test, preprocessed_test, 'PNEUMONIA')\n",
    "    \n",
    "    \n",
    "    aug_train = augment_dataset(normal_train, preprocessed_train, train_aug_needed)\n",
    "    aug_val = augment_dataset(normal_val, preprocessed_val, val_aug_needed)\n",
    "    aug_test = augment_dataset(normal_test, preprocessed_test, test_aug_needed)\n",
    "    \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\nRésumé du prétraitement optimisé:\")\n",
    "    print(f\"Temps total: {elapsed_time:.2f} secondes\")\n",
    "    print(f\"Images traitées: {total_processed}\")\n",
    "    print(f\"Succès: {successful}\")\n",
    "    print(f\"Échecs: {failed}\")\n",
    "    print(f\"Taux de réussite: {(successful/total_processed)*100:.2f}%\")\n",
    "    \n",
    "    \n",
    "    train_normal_count = len(os.listdir(os.path.join(preprocessed_train, 'NORMAL')))\n",
    "    train_pneumonia_count = len(os.listdir(os.path.join(preprocessed_train, 'PNEUMONIA')))\n",
    "    val_normal_count = len(os.listdir(os.path.join(preprocessed_val, 'NORMAL')))\n",
    "    val_pneumonia_count = len(os.listdir(os.path.join(preprocessed_val, 'PNEUMONIA')))\n",
    "    test_normal_count = len(os.listdir(os.path.join(preprocessed_test, 'NORMAL')))\n",
    "    test_pneumonia_count = len(os.listdir(os.path.join(preprocessed_test, 'PNEUMONIA')))\n",
    "    \n",
    "    print(\"\\nDistribution finale (toutes images originales conservées + équilibre 50/50):\")\n",
    "    print(f\"Train: {train_normal_count} normales, {train_pneumonia_count} pneumonies\")\n",
    "    print(f\"Validation: {val_normal_count} normales, {val_pneumonia_count} pneumonies\")\n",
    "    print(f\"Test: {test_normal_count} normales, {test_pneumonia_count} pneumonies\")\n",
    "    print(f\"Total: {train_normal_count + train_pneumonia_count + val_normal_count + val_pneumonia_count + test_normal_count + test_pneumonia_count} images\")\n",
    "\n",
    "\n",
    "create_optimized_balanced_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27942019",
   "metadata": {},
   "source": [
    "# Analyse statistique du dataset prétraité\n",
    "\n",
    "Cette cellule analyse le dataset prétraité pour vérifier les résultats de nos transformations. Nous observons que toutes les images ont désormais une taille uniforme de 256×256 pixels et sont en niveaux de gris. Les classes sont parfaitement équilibrées (ratio 1:1) dans chaque ensemble grâce à l'augmentation des images normales. Les différences de contraste entre images normales (61.04) et pneumonies (55.19) ont été préservées, caractéristique qui pourrait aider notre modèle à distinguer les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c6ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "preprocessed_path = 'preprocessed_chest_xray'\n",
    "folders = ['train', 'test', 'val']\n",
    "\n",
    "def analyze_image(img_path):\n",
    "    \"\"\"Analyse une image et extrait ses caractéristiques\"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size\n",
    "        img_mode = img.mode\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        \n",
    "        if 'train' in img_path:\n",
    "            dataset = 'Train'\n",
    "        elif 'test' in img_path:\n",
    "            dataset = 'Test'\n",
    "        else:\n",
    "            dataset = 'Validation'\n",
    "        \n",
    "        \n",
    "        is_augmented = 'aug' in os.path.basename(img_path)\n",
    "        \n",
    "        return {\n",
    "            'width': img_width,\n",
    "            'height': img_height,\n",
    "            'mode': img_mode,\n",
    "            'mean_pixel': np.mean(img_array),\n",
    "            'std_pixel': np.std(img_array),\n",
    "            'class': 'Normal' if 'NORMAL' in img_path else 'Pneumonia',\n",
    "            'dataset': dataset,\n",
    "            'augmented': is_augmented\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'analyse de {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "all_files = []\n",
    "for folder in folders:\n",
    "    \n",
    "    normal_path = os.path.join(preprocessed_path, folder, 'NORMAL')\n",
    "    if os.path.exists(normal_path):\n",
    "        normal_files = [os.path.join(normal_path, f) for f in os.listdir(normal_path) \n",
    "                    if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "        all_files.extend(normal_files)\n",
    "    \n",
    "    \n",
    "    pneumonia_path = os.path.join(preprocessed_path, folder, 'PNEUMONIA')\n",
    "    if os.path.exists(pneumonia_path):\n",
    "        pneumonia_files = [os.path.join(pneumonia_path, f) for f in os.listdir(pneumonia_path) \n",
    "                      if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "        all_files.extend(pneumonia_files)\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Analyse de {len(all_files)} images dans le dataset prétraité...\")\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, img_path in enumerate(all_files):\n",
    "    if i % 500 == 0 and i > 0: \n",
    "        print(f\"Analysé {i}/{len(all_files)} images...\")\n",
    "    result = analyze_image(img_path)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Analyse terminée en {elapsed_time:.2f} secondes\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "normal_df = df[df['class'] == 'Normal']\n",
    "pneumonia_df = df[df['class'] == 'Pneumonia']\n",
    "original_normal_df = normal_df[~normal_df['augmented']]\n",
    "augmented_normal_df = normal_df[normal_df['augmented']]\n",
    "\n",
    "\n",
    "print(f\"\\n===== TAILLE DU DATASET =====\")\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Images normales: {len(normal_df)} (dont {len(original_normal_df)} originales, {len(augmented_normal_df)} augmentées)\")\n",
    "print(f\"Images pneumonie: {len(pneumonia_df)}\")\n",
    "\n",
    "\n",
    "for dataset in ['Train', 'Test', 'Validation']:\n",
    "    dataset_df = df[df['dataset'] == dataset]\n",
    "    dataset_normal = dataset_df[dataset_df['class'] == 'Normal']\n",
    "    dataset_pneumonia = dataset_df[dataset_df['class'] == 'Pneumonia']\n",
    "    \n",
    "    original_normal = dataset_normal[~dataset_normal['augmented']]\n",
    "    augmented_normal = dataset_normal[dataset_normal['augmented']]\n",
    "    \n",
    "    print(f\"\\n===== ENSEMBLE {dataset.upper()} ({len(dataset_df)} images) =====\")\n",
    "    print(f\"Normal: {len(dataset_normal)} images (dont {len(original_normal)} originales, {len(augmented_normal)} augmentées)\")\n",
    "    print(f\"Pneumonie: {len(dataset_pneumonia)} images\")\n",
    "    ratio = len(dataset_normal)/len(dataset_pneumonia)\n",
    "    print(f\"Ratio Normal:Pneumonie = {ratio:.2f}:1\")\n",
    "\n",
    "\n",
    "print(\"\\n===== DIMENSIONS =====\")\n",
    "print(f\"Largeur moyenne (Normal originales): {original_normal_df['width'].mean():.1f}px\")\n",
    "print(f\"Largeur moyenne (Normal augmentées): {augmented_normal_df['width'].mean():.1f}px\")\n",
    "print(f\"Largeur moyenne (Pneumonie): {pneumonia_df['width'].mean():.1f}px\")\n",
    "print(f\"Hauteur moyenne (Normal originales): {original_normal_df['height'].mean():.1f}px\")\n",
    "print(f\"Hauteur moyenne (Normal augmentées): {augmented_normal_df['height'].mean():.1f}px\")\n",
    "print(f\"Hauteur moyenne (Pneumonie): {pneumonia_df['height'].mean():.1f}px\")\n",
    "\n",
    "\n",
    "print(\"\\n===== LUMINOSITÉ =====\")\n",
    "print(f\"Luminosité moyenne (Normal originales): {original_normal_df['mean_pixel'].mean():.2f}\")\n",
    "print(f\"Luminosité moyenne (Normal augmentées): {augmented_normal_df['mean_pixel'].mean():.2f}\")\n",
    "print(f\"Luminosité moyenne (Pneumonie): {pneumonia_df['mean_pixel'].mean():.2f}\")\n",
    "\n",
    "\n",
    "print(\"\\n===== CONTRASTE =====\")\n",
    "print(f\"Contraste moyen (Normal originales): {original_normal_df['std_pixel'].mean():.2f}\")\n",
    "print(f\"Contraste moyen (Normal augmentées): {augmented_normal_df['std_pixel'].mean():.2f}\")\n",
    "print(f\"Contraste moyen (Pneumonie): {pneumonia_df['std_pixel'].mean():.2f}\")\n",
    "\n",
    "\n",
    "print(\"\\n===== VARIABILITÉ ENTRE IMAGES =====\")\n",
    "print(f\"Variabilité de luminosité (Normal originales): {original_normal_df['mean_pixel'].std():.2f}\")\n",
    "print(f\"Variabilité de luminosité (Normal augmentées): {augmented_normal_df['mean_pixel'].std():.2f}\")\n",
    "print(f\"Variabilité de luminosité (Pneumonie): {pneumonia_df['mean_pixel'].std():.2f}\")\n",
    "print(f\"Variabilité de contraste (Normal originales): {original_normal_df['std_pixel'].std():.2f}\")\n",
    "print(f\"Variabilité de contraste (Normal augmentées): {augmented_normal_df['std_pixel'].std():.2f}\")\n",
    "print(f\"Variabilité de contraste (Pneumonie): {pneumonia_df['std_pixel'].std():.2f}\")\n",
    "\n",
    "\n",
    "print(\"\\n===== MODES D'IMAGE =====\")\n",
    "print(df['mode'].value_counts())\n",
    "\n",
    "\n",
    "all_sizes = df.groupby(['width', 'height']).size().reset_index(name='count')\n",
    "print(\"\\n===== VARIÉTÉ DE TAILLES =====\")\n",
    "print(f\"Nombre de dimensions différentes: {len(all_sizes)}\")\n",
    "print(f\"Dimensions les plus courantes: {all_sizes.sort_values('count', ascending=False).head(1).iloc[0]['width']}×{all_sizes.sort_values('count', ascending=False).head(1).iloc[0]['height']}\")\n",
    "print(f\"Dimensions min: {df['width'].min()}×{df['height'].min()}\")\n",
    "print(f\"Dimensions max: {df['width'].max()}×{df['height'].max()}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(pneumonia_df['mean_pixel'], bins=30, alpha=0.7, color='red', label='Pneumonie')\n",
    "plt.hist(original_normal_df['mean_pixel'], bins=30, alpha=0.7, color='blue', label='Normal (Original)')\n",
    "plt.hist(augmented_normal_df['mean_pixel'], bins=30, alpha=0.7, color='green', label='Normal (Augmenté)')\n",
    "plt.xlabel('Luminosité moyenne', fontsize=12)\n",
    "plt.ylabel('Nombre d\\'images', fontsize=12)\n",
    "plt.title('Distribution des luminosités', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(pneumonia_df['std_pixel'], bins=30, alpha=0.7, color='red', label='Pneumonie')\n",
    "plt.hist(original_normal_df['std_pixel'], bins=30, alpha=0.7, color='blue', label='Normal (Original)')\n",
    "plt.hist(augmented_normal_df['std_pixel'], bins=30, alpha=0.7, color='green', label='Normal (Augmenté)')\n",
    "plt.xlabel('Contraste (écart-type)', fontsize=12)\n",
    "plt.ylabel('Nombre d\\'images', fontsize=12)\n",
    "plt.title('Distribution des contrastes', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n===== CONCLUSION DE L'ANALYSE =====\")\n",
    "print(\"1. Équilibre des classes: Parfaitement équilibré dans chaque ensemble (ratio 1:1)\")\n",
    "print(\"2. Dimensions: Toutes les images ont été standardisées à la même taille\")\n",
    "print(\"3. Distribution par ensemble: Respecte la répartition 80/10/10 (train/val/test)\")\n",
    "print(\"4. Images augmentées: Comportement similaire aux originales en termes de contraste et luminosité\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pneumonia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
