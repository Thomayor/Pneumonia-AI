{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ecf127",
   "metadata": {},
   "source": [
    "# Caractéristiques avancées pour la détection de pneumonie\n",
    "\n",
    "Constatant que le fine-tuning des hyperparamètres de Random Forest ne permet pas de dépasser 82% d'accuracy, nous explorons dans ce notebook l'extraction de caractéristiques avancées avec HOG (Histogram of Oriented Gradients) et LBP (Local Binary Patterns).\n",
    "\n",
    "## Pourquoi ces descripteurs améliorent les performances\n",
    "\n",
    "Contrairement aux statistiques simples (moyennes, écarts-types) qui ne capturent que des informations globales, HOG et LBP extraient:\n",
    "- **Contours et structures** (HOG): détecte les gradients d'intensité révélateurs des opacités pneumoniques\n",
    "- **Textures locales** (LBP): capture les motifs subtils des infiltrats et altérations tissulaires\n",
    "\n",
    "La combinaison HOG+LBP offre une représentation complémentaire et bien plus riche des radiographies, permettant au même algorithme Random Forest d'atteindre des performances nettement supérieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08314e",
   "metadata": {},
   "source": [
    "# Vérification des dossiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8629d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"Dossier '{models_dir}' créé avec succès.\")\n",
    "else:\n",
    "    print(f\"Le dossier '{models_dir}' existe déjà.\")\n",
    "    \n",
    "preprocessed_base = 'preprocessed_chest_xray'\n",
    "train_dir = os.path.join(preprocessed_base, 'train')\n",
    "val_dir = os.path.join(preprocessed_base, 'val')\n",
    "test_dir = os.path.join(preprocessed_base, 'test')\n",
    "\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Attention: Le dossier {directory} n'existe pas!\")\n",
    "    else:\n",
    "        normal_count = len(os.listdir(os.path.join(directory, 'NORMAL')))\n",
    "        pneumonia_count = len(os.listdir(os.path.join(directory, 'PNEUMONIA')))\n",
    "        print(f\"{directory}: {normal_count} images normales, {pneumonia_count} images pneumonie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14906681",
   "metadata": {},
   "source": [
    "# Définition des fonctions pour extraire les caractéristiques HOG et LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img_array):\n",
    "    \"\"\"Extrait les caractéristiques HOG d'une image\"\"\"\n",
    "    hog_features = hog(img_array, orientations=9, \n",
    "                       pixels_per_cell=(16, 16),\n",
    "                       cells_per_block=(2, 2), \n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=False,\n",
    "                       transform_sqrt=True)\n",
    "    return hog_features\n",
    "\n",
    "def extract_lbp_features(img_array, P=24, R=3):\n",
    "    \"\"\"Extrait les caractéristiques LBP d'une image\"\"\"\n",
    "    lbp = local_binary_pattern(img_array, P=P, R=R, method='uniform')\n",
    "    n_bins = P + 2\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "def load_and_extract_advanced_features(directory, feature_type='hog', max_samples=None):\n",
    "    \"\"\"\n",
    "    Charge les images depuis un répertoire et extrait les caractéristiques HOG ou LBP.\n",
    "    \n",
    "    Paramètres:\n",
    "    -----------\n",
    "    directory : str\n",
    "        Chemin vers le répertoire contenant les sous-dossiers 'NORMAL' et 'PNEUMONIA'\n",
    "    feature_type : str\n",
    "        Type de caractéristiques à extraire ('hog', 'lbp', ou 'both')\n",
    "    max_samples : int ou None\n",
    "        Nombre maximum d'échantillons à charger par classe (None pour tout charger)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_label, class_name in enumerate(['NORMAL', 'PNEUMONIA']):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        \n",
    "\n",
    "        image_files = [f for f in os.listdir(class_dir) \n",
    "                      if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
    "        \n",
    "\n",
    "        if max_samples is not None:\n",
    "            image_files = image_files[:max_samples]\n",
    "        \n",
    "        print(f\"Chargement de {len(image_files)} images {class_name}...\")\n",
    "        \n",
    "\n",
    "        for i, img_file in enumerate(image_files):\n",
    "    \n",
    "            if i > 0 and i % 100 == 0:\n",
    "                print(f\"  - {i}/{len(image_files)} images traitées...\")\n",
    "            \n",
    "    \n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "    \n",
    "            if feature_type == 'hog':\n",
    "                img_features = extract_hog_features(img_array)\n",
    "            elif feature_type == 'lbp':\n",
    "                img_features = extract_lbp_features(img_array)\n",
    "            elif feature_type == 'both':\n",
    "                hog_features = extract_hog_features(img_array)\n",
    "                lbp_features = extract_lbp_features(img_array)\n",
    "                img_features = np.concatenate((hog_features, lbp_features))\n",
    "            \n",
    "    \n",
    "            features.append(img_features)\n",
    "            labels.append(class_label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3dde3",
   "metadata": {},
   "source": [
    "# Extraction et sauvegarde des caractéristiques HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtraction des caractéristiques HOG...\")\n",
    "train_hog_features, train_labels = load_and_extract_advanced_features(train_dir, feature_type='hog')\n",
    "val_hog_features, val_labels = load_and_extract_advanced_features(val_dir, feature_type='hog')\n",
    "test_hog_features, test_labels = load_and_extract_advanced_features(test_dir, feature_type='hog')\n",
    "\n",
    "print(\"\\nDimensions des caractéristiques HOG:\")\n",
    "print(f\"Train: {train_hog_features.shape}\")\n",
    "print(f\"Validation: {val_hog_features.shape}\")\n",
    "print(f\"Test: {test_hog_features.shape}\")\n",
    "\n",
    "with open(os.path.join(models_dir, 'train_hog_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_hog_features, f)\n",
    "with open(os.path.join(models_dir, 'val_hog_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_hog_features, f)\n",
    "with open(os.path.join(models_dir, 'test_hog_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_hog_features, f)\n",
    "with open(os.path.join(models_dir, 'train_labels.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_labels, f)\n",
    "with open(os.path.join(models_dir, 'val_labels.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_labels, f)\n",
    "with open(os.path.join(models_dir, 'test_labels.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_labels, f)\n",
    "print(\"Caractéristiques HOG sauvegardées avec succès dans le dossier 'models'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa6a93",
   "metadata": {},
   "source": [
    "# Entraînement et évaluation du modèle HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nEntraînement du modèle Random Forest avec caractéristiques HOG...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_hog_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,           \n",
    "    min_samples_leaf=5,     \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf_hog_model.fit(train_hog_features, train_labels)\n",
    "\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Modèle entraîné en {training_time:.2f} secondes\")\n",
    "\n",
    "\n",
    "print(\"\\nÉvaluation du modèle avec caractéristiques HOG:\")\n",
    "\n",
    "\n",
    "train_predictions = rf_hog_model.predict(train_hog_features)\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Accuracy Train: {train_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "val_predictions = rf_hog_model.predict(val_hog_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "val_precision = precision_score(val_labels, val_predictions)\n",
    "val_recall = recall_score(val_labels, val_predictions)\n",
    "val_f1 = f1_score(val_labels, val_predictions)\n",
    "\n",
    "print(f\"Accuracy Validation: {val_accuracy:.4f}\")\n",
    "print(f\"Precision Validation: {val_precision:.4f}\")\n",
    "print(f\"Recall Validation: {val_recall:.4f}\")\n",
    "print(f\"F1 Score Validation: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "test_predictions = rf_hog_model.predict(test_hog_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions)\n",
    "test_recall = recall_score(test_labels, test_predictions)\n",
    "test_f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Accuracy Test: {test_accuracy:.4f}\")\n",
    "print(f\"Precision Test: {test_precision:.4f}\")\n",
    "print(f\"Recall Test: {test_recall:.4f}\")\n",
    "print(f\"F1 Score Test: {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nMatrice de confusion (Test):\")\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "with open(os.path.join(models_dir, 'rf_hog_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(rf_hog_model, f)\n",
    "print(\"Modèle HOG sauvegardé avec succès dans le dossier 'models'!\")\n",
    "\n",
    "\n",
    "hog_metrics = {\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_precision': test_precision,\n",
    "    'test_recall': test_recall,\n",
    "    'test_f1': test_f1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba27762",
   "metadata": {},
   "source": [
    "# Extraction et évaluation des caractéristiques LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nExtraction des caractéristiques LBP...\")\n",
    "train_lbp_features, _ = load_and_extract_advanced_features(train_dir, feature_type='lbp')\n",
    "val_lbp_features, _ = load_and_extract_advanced_features(val_dir, feature_type='lbp')\n",
    "test_lbp_features, _ = load_and_extract_advanced_features(test_dir, feature_type='lbp')\n",
    "\n",
    "print(\"\\nDimensions des caractéristiques LBP:\")\n",
    "print(f\"Train: {train_lbp_features.shape}\")\n",
    "print(f\"Validation: {val_lbp_features.shape}\")\n",
    "print(f\"Test: {test_lbp_features.shape}\")\n",
    "\n",
    "with open(os.path.join(models_dir, 'train_lbp_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_lbp_features, f)\n",
    "with open(os.path.join(models_dir, 'val_lbp_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_lbp_features, f)\n",
    "with open(os.path.join(models_dir, 'test_lbp_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_lbp_features, f)\n",
    "print(\"Caractéristiques LBP sauvegardées avec succès dans le dossier 'models'!\")\n",
    "\n",
    "print(\"\\nEntraînement du modèle Random Forest avec caractéristiques LBP...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_lbp_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_lbp_model.fit(train_lbp_features, train_labels)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Modèle entraîné en {training_time:.2f} secondes\")\n",
    "\n",
    "print(\"\\nÉvaluation du modèle avec caractéristiques LBP:\")\n",
    "\n",
    "train_predictions = rf_lbp_model.predict(train_lbp_features)\n",
    "train_accuracy_lbp = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Accuracy Train: {train_accuracy_lbp:.4f}\")\n",
    "\n",
    "val_predictions = rf_lbp_model.predict(val_lbp_features)\n",
    "val_accuracy_lbp = accuracy_score(val_labels, val_predictions)\n",
    "val_precision_lbp = precision_score(val_labels, val_predictions)\n",
    "val_recall_lbp = recall_score(val_labels, val_predictions)\n",
    "val_f1_lbp = f1_score(val_labels, val_predictions)\n",
    "\n",
    "print(f\"Accuracy Validation: {val_accuracy_lbp:.4f}\")\n",
    "print(f\"Precision Validation: {val_precision_lbp:.4f}\")\n",
    "print(f\"Recall Validation: {val_recall_lbp:.4f}\")\n",
    "print(f\"F1 Score Validation: {val_f1_lbp:.4f}\")\n",
    "\n",
    "test_predictions = rf_lbp_model.predict(test_lbp_features)\n",
    "test_accuracy_lbp = accuracy_score(test_labels, test_predictions)\n",
    "test_precision_lbp = precision_score(test_labels, test_predictions)\n",
    "test_recall_lbp = recall_score(test_labels, test_predictions)\n",
    "test_f1_lbp = f1_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Accuracy Test: {test_accuracy_lbp:.4f}\")\n",
    "print(f\"Precision Test: {test_precision_lbp:.4f}\")\n",
    "print(f\"Recall Test: {test_recall_lbp:.4f}\")\n",
    "print(f\"F1 Score Test: {test_f1_lbp:.4f}\")\n",
    "\n",
    "print(\"\\nMatrice de confusion (Test):\")\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "print(conf_matrix)\n",
    "\n",
    "with open(os.path.join(models_dir, 'rf_lbp_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(rf_lbp_model, f)\n",
    "print(\"Modèle LBP sauvegardé avec succès dans le dossier 'models'!\")\n",
    "\n",
    "lbp_metrics = {\n",
    "    'train_accuracy': train_accuracy_lbp,\n",
    "    'val_accuracy': val_accuracy_lbp,\n",
    "    'test_accuracy': test_accuracy_lbp,\n",
    "    'test_precision': test_precision_lbp,\n",
    "    'test_recall': test_recall_lbp,\n",
    "    'test_f1': test_f1_lbp\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e7447",
   "metadata": {},
   "source": [
    "# Extraction et évaluation des caractéristiques combinées HOG+LBP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nExtraction des caractéristiques combinées HOG+LBP...\")\n",
    "train_combined_features, _ = load_and_extract_advanced_features(train_dir, feature_type='both')\n",
    "val_combined_features, _ = load_and_extract_advanced_features(val_dir, feature_type='both')\n",
    "test_combined_features, _ = load_and_extract_advanced_features(test_dir, feature_type='both')\n",
    "\n",
    "print(\"\\nDimensions des caractéristiques combinées:\")\n",
    "print(f\"Train: {train_combined_features.shape}\")\n",
    "print(f\"Validation: {val_combined_features.shape}\")\n",
    "print(f\"Test: {test_combined_features.shape}\")\n",
    "\n",
    "with open(os.path.join(models_dir, 'train_combined_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_combined_features, f)\n",
    "with open(os.path.join(models_dir, 'val_combined_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_combined_features, f)\n",
    "with open(os.path.join(models_dir, 'test_combined_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_combined_features, f)\n",
    "print(\"Caractéristiques combinées sauvegardées avec succès dans le dossier 'models'!\")\n",
    "\n",
    "print(\"\\nEntraînement du modèle Random Forest avec caractéristiques combinées HOG+LBP...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_combined_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_combined_model.fit(train_combined_features, train_labels)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Modèle entraîné en {training_time:.2f} secondes\")\n",
    "\n",
    "print(\"\\nÉvaluation du modèle avec caractéristiques combinées HOG+LBP:\")\n",
    "\n",
    "train_predictions = rf_combined_model.predict(train_combined_features)\n",
    "train_accuracy_combined = accuracy_score(train_labels, train_predictions)\n",
    "print(f\"Accuracy Train: {train_accuracy_combined:.4f}\")\n",
    "\n",
    "val_predictions = rf_combined_model.predict(val_combined_features)\n",
    "val_accuracy_combined = accuracy_score(val_labels, val_predictions)\n",
    "val_precision_combined = precision_score(val_labels, val_predictions)\n",
    "val_recall_combined = recall_score(val_labels, val_predictions)\n",
    "val_f1_combined = f1_score(val_labels, val_predictions)\n",
    "\n",
    "print(f\"Accuracy Validation: {val_accuracy_combined:.4f}\")\n",
    "print(f\"Precision Validation: {val_precision_combined:.4f}\")\n",
    "print(f\"Recall Validation: {val_recall_combined:.4f}\")\n",
    "print(f\"F1 Score Validation: {val_f1_combined:.4f}\")\n",
    "\n",
    "test_predictions = rf_combined_model.predict(test_combined_features)\n",
    "test_accuracy_combined = accuracy_score(test_labels, test_predictions)\n",
    "test_precision_combined = precision_score(test_labels, test_predictions)\n",
    "test_recall_combined = recall_score(test_labels, test_predictions)\n",
    "test_f1_combined = f1_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Accuracy Test: {test_accuracy_combined:.4f}\")\n",
    "print(f\"Precision Test: {test_precision_combined:.4f}\")\n",
    "print(f\"Recall Test: {test_recall_combined:.4f}\")\n",
    "print(f\"F1 Score Test: {test_f1_combined:.4f}\")\n",
    "\n",
    "print(\"\\nMatrice de confusion (Test):\")\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "print(conf_matrix)\n",
    "\n",
    "with open(os.path.join(models_dir, 'rf_combined_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(rf_combined_model, f)\n",
    "print(\"Modèle combiné sauvegardé avec succès dans le dossier 'models'!\")\n",
    "\n",
    "combined_metrics = {\n",
    "    'train_accuracy': train_accuracy_combined,\n",
    "    'val_accuracy': val_accuracy_combined, \n",
    "    'test_accuracy': test_accuracy_combined,\n",
    "    'test_precision': test_precision_combined,\n",
    "    'test_recall': test_recall_combined,\n",
    "    'test_f1': test_f1_combined\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125acfa1",
   "metadata": {},
   "source": [
    "# Comparaison des modèles et conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c16569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== COMPARAISON DES MODÈLES =====\")\n",
    "models = ['Statistiques (Notebook 4)', 'HOG', 'LBP', 'HOG + LBP']\n",
    "\n",
    "previous_model_train = 0.8773\n",
    "previous_model_val = 0.7986\n",
    "previous_model_test = 0.8189\n",
    "\n",
    "comparison_data = {\n",
    "    'Modèle': models,\n",
    "    'Accuracy Train': [\n",
    "        previous_model_train, \n",
    "        hog_metrics['train_accuracy'], \n",
    "        lbp_metrics['train_accuracy'], \n",
    "        combined_metrics['train_accuracy']\n",
    "    ],\n",
    "    'Accuracy Validation': [\n",
    "        previous_model_val,\n",
    "        hog_metrics['val_accuracy'],\n",
    "        lbp_metrics['val_accuracy'],\n",
    "        combined_metrics['val_accuracy']\n",
    "    ],\n",
    "    'Accuracy Test': [\n",
    "        previous_model_test, \n",
    "        hog_metrics['test_accuracy'], \n",
    "        lbp_metrics['test_accuracy'], \n",
    "        combined_metrics['test_accuracy']\n",
    "    ],\n",
    "    'Precision Test': [\n",
    "        'N/A',\n",
    "        f\"{hog_metrics['test_precision']:.4f}\",\n",
    "        f\"{lbp_metrics['test_precision']:.4f}\",\n",
    "        f\"{combined_metrics['test_precision']:.4f}\"\n",
    "    ],\n",
    "    'Recall Test': [\n",
    "        'N/A',\n",
    "        f\"{hog_metrics['test_recall']:.4f}\",\n",
    "        f\"{lbp_metrics['test_recall']:.4f}\",\n",
    "        f\"{combined_metrics['test_recall']:.4f}\"\n",
    "    ],\n",
    "    'F1 Score Test': [\n",
    "        'N/A',\n",
    "        f\"{hog_metrics['test_f1']:.4f}\",\n",
    "        f\"{lbp_metrics['test_f1']:.4f}\",\n",
    "        f\"{combined_metrics['test_f1']:.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df)\n",
    "\n",
    "comparison_df.to_csv(os.path.join(models_dir, 'model_comparison.csv'), index=False)\n",
    "print(f\"Résultats de comparaison sauvegardés dans {os.path.join(models_dir, 'model_comparison.csv')}\")\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(models))\n",
    "\n",
    "plt.bar(index, comparison_df['Accuracy Train'], bar_width, label='Train', color='blue', alpha=0.7)\n",
    "plt.bar(index + bar_width, comparison_df['Accuracy Validation'], bar_width, label='Validation', color='green', alpha=0.7)\n",
    "plt.bar(index + 2*bar_width, comparison_df['Accuracy Test'], bar_width, label='Test', color='red', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Modèle', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Comparaison des performances des différentes approches', fontsize=14)\n",
    "plt.xticks(index + bar_width, models, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig(os.path.join(models_dir, 'model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n===== CONCLUSION =====\")\n",
    "best_model = 'HOG+LBP'\n",
    "improvement = (combined_metrics['test_accuracy'] - previous_model_test) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pneumonia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
