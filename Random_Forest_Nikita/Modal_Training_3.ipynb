{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85602355",
   "metadata": {},
   "source": [
    "# Entraînement du modèle Random Forest pour la détection de pneumonie\n",
    "\n",
    "Ce notebook implémente l'entraînement d'un modèle Random Forest pour détecter la pneumonie à partir de radiographies pulmonaires. Nous utiliserons les images prétraitées du notebook précédent.\n",
    "\n",
    "Les étapes principales sont:\n",
    "1. Chargement des images prétraitées\n",
    "2. Extraction des caractéristiques des images\n",
    "3. Entraînement du modèle Random Forest \n",
    "4. Évaluation des performances du modèle\n",
    "5. Optimisation des hyperparamètres\n",
    "\n",
    "**os:** pour naviguer dans les dossiers d'images\n",
    "\n",
    "**numpy:** pour manipuler les tableaux de données\n",
    "\n",
    "**pandas:** pour gérer les dataframes\n",
    "\n",
    "**matplotlib:** pour visualiser les résultats\n",
    "\n",
    "**PIL:** pour charger les images\n",
    "\n",
    "**sklearn:** pour implémenter le modèle Random Forest et évaluer ses performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b815d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e5db0",
   "metadata": {},
   "source": [
    "# La cellule ci-dessous vérifie que nous pouvons accéder aux images prétraitées et affiche leur répartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f0fa72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_chest_xray/train: 3418 images normales, 3418 images pneumonie\n",
      "preprocessed_chest_xray/val: 427 images normales, 427 images pneumonie\n",
      "preprocessed_chest_xray/test: 428 images normales, 428 images pneumonie\n"
     ]
    }
   ],
   "source": [
    "preprocessed_base = 'preprocessed_chest_xray'\n",
    "train_dir = os.path.join(preprocessed_base, 'train')\n",
    "val_dir = os.path.join(preprocessed_base, 'val')\n",
    "test_dir = os.path.join(preprocessed_base, 'test')\n",
    "\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Attention: Le dossier {directory} n'existe pas!\")\n",
    "    else:\n",
    "        normal_count = len(os.listdir(os.path.join(directory, 'NORMAL')))\n",
    "        pneumonia_count = len(os.listdir(os.path.join(directory, 'PNEUMONIA')))\n",
    "        print(f\"{directory}: {normal_count} images normales, {pneumonia_count} images pneumonie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1f986",
   "metadata": {},
   "source": [
    "# Fonction d'extraction des charactéristiques de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8b0fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract_features(directory, max_samples=None):\n",
    "    \"\"\"\n",
    "    Charge les images depuis un répertoire et extrait des caractéristiques basiques.\n",
    "    \n",
    "    Paramètres:\n",
    "    -----------\n",
    "    directory : str\n",
    "        Chemin vers le répertoire contenant les sous-dossiers 'NORMAL' et 'PNEUMONIA'\n",
    "    max_samples : int ou None\n",
    "        Nombre maximum d'échantillons à charger par classe (None pour tout charger)\n",
    "        \n",
    "    Retours:\n",
    "    --------\n",
    "    features : numpy.ndarray\n",
    "        Tableau des caractéristiques extraites (statistiques basiques)\n",
    "    labels : numpy.ndarray\n",
    "        Tableau des étiquettes (0 pour normal, 1 pour pneumonie)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_label, class_name in enumerate(['NORMAL', 'PNEUMONIA']):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        \n",
    "\n",
    "        image_files = [f for f in os.listdir(class_dir) \n",
    "                      if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
    "        \n",
    "\n",
    "        if max_samples is not None:\n",
    "            image_files = image_files[:max_samples]\n",
    "        \n",
    "        print(f\"Chargement de {len(image_files)} images {class_name}...\")\n",
    "        \n",
    "\n",
    "        for i, img_file in enumerate(image_files):\n",
    "    \n",
    "            if i > 0 and i % 100 == 0:\n",
    "                print(f\"  - {i}/{len(image_files)} images traitées...\")\n",
    "            \n",
    "    \n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "    \n",
    "    \n",
    "            mean_val = np.mean(img_array)\n",
    "            std_val = np.std(img_array)  \n",
    "            min_val = np.min(img_array)  \n",
    "            max_val = np.max(img_array)  \n",
    "            median_val = np.median(img_array)\n",
    "            \n",
    "    \n",
    "            h, w = img_array.shape\n",
    "            h_mid, w_mid = h // 2, w // 2\n",
    "            \n",
    "    \n",
    "            q1 = img_array[:h_mid, :w_mid]\n",
    "            q1_mean = np.mean(q1)\n",
    "            q1_std = np.std(q1)\n",
    "            \n",
    "    \n",
    "            q2 = img_array[:h_mid, w_mid:]\n",
    "            q2_mean = np.mean(q2)\n",
    "            q2_std = np.std(q2)\n",
    "            \n",
    "    \n",
    "            q3 = img_array[h_mid:, :w_mid]\n",
    "            q3_mean = np.mean(q3)\n",
    "            q3_std = np.std(q3)\n",
    "            \n",
    "    \n",
    "            q4 = img_array[h_mid:, w_mid:]\n",
    "            q4_mean = np.mean(q4)\n",
    "            q4_std = np.std(q4)\n",
    "            \n",
    "    \n",
    "            img_features = [\n",
    "                mean_val, std_val, min_val, max_val, median_val,\n",
    "                q1_mean, q1_std, q2_mean, q2_std,\n",
    "                q3_mean, q3_std, q4_mean, q4_std\n",
    "            ]\n",
    "            \n",
    "    \n",
    "            features.append(img_features)\n",
    "            labels.append(class_label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d626a5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7dc0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des caractéristiques de l'ensemble d'entraînement...\n",
      "Chargement de 3418 images NORMAL...\n",
      "  - 100/3418 images traitées...\n",
      "  - 200/3418 images traitées...\n",
      "  - 300/3418 images traitées...\n",
      "  - 400/3418 images traitées...\n",
      "  - 500/3418 images traitées...\n",
      "  - 600/3418 images traitées...\n",
      "  - 700/3418 images traitées...\n",
      "  - 800/3418 images traitées...\n",
      "  - 900/3418 images traitées...\n",
      "  - 1000/3418 images traitées...\n",
      "  - 1100/3418 images traitées...\n",
      "  - 1200/3418 images traitées...\n",
      "  - 1300/3418 images traitées...\n",
      "  - 1400/3418 images traitées...\n",
      "  - 1500/3418 images traitées...\n",
      "  - 1600/3418 images traitées...\n",
      "  - 1700/3418 images traitées...\n",
      "  - 1800/3418 images traitées...\n",
      "  - 1900/3418 images traitées...\n",
      "  - 2000/3418 images traitées...\n",
      "  - 2100/3418 images traitées...\n",
      "  - 2200/3418 images traitées...\n",
      "  - 2300/3418 images traitées...\n",
      "  - 2400/3418 images traitées...\n",
      "  - 2500/3418 images traitées...\n",
      "  - 2600/3418 images traitées...\n",
      "  - 2700/3418 images traitées...\n",
      "  - 2800/3418 images traitées...\n",
      "  - 2900/3418 images traitées...\n",
      "  - 3000/3418 images traitées...\n",
      "  - 3100/3418 images traitées...\n",
      "  - 3200/3418 images traitées...\n",
      "  - 3300/3418 images traitées...\n",
      "  - 3400/3418 images traitées...\n",
      "Chargement de 3418 images PNEUMONIA...\n",
      "  - 100/3418 images traitées...\n",
      "  - 200/3418 images traitées...\n",
      "  - 300/3418 images traitées...\n",
      "  - 400/3418 images traitées...\n",
      "  - 500/3418 images traitées...\n",
      "  - 600/3418 images traitées...\n",
      "  - 700/3418 images traitées...\n",
      "  - 800/3418 images traitées...\n",
      "  - 900/3418 images traitées...\n",
      "  - 1000/3418 images traitées...\n",
      "  - 1100/3418 images traitées...\n",
      "  - 1200/3418 images traitées...\n",
      "  - 1300/3418 images traitées...\n",
      "  - 1400/3418 images traitées...\n",
      "  - 1500/3418 images traitées...\n",
      "  - 1600/3418 images traitées...\n",
      "  - 1700/3418 images traitées...\n",
      "  - 1800/3418 images traitées...\n",
      "  - 1900/3418 images traitées...\n",
      "  - 2000/3418 images traitées...\n",
      "  - 2100/3418 images traitées...\n",
      "  - 2200/3418 images traitées...\n",
      "  - 2300/3418 images traitées...\n",
      "  - 2400/3418 images traitées...\n",
      "  - 2500/3418 images traitées...\n",
      "  - 2600/3418 images traitées...\n",
      "  - 2700/3418 images traitées...\n",
      "  - 2800/3418 images traitées...\n",
      "  - 2900/3418 images traitées...\n",
      "  - 3000/3418 images traitées...\n",
      "  - 3100/3418 images traitées...\n",
      "  - 3200/3418 images traitées...\n",
      "  - 3300/3418 images traitées...\n",
      "  - 3400/3418 images traitées...\n",
      "\n",
      "Extraction des caractéristiques de l'ensemble de validation...\n",
      "Chargement de 427 images NORMAL...\n",
      "  - 100/427 images traitées...\n",
      "  - 200/427 images traitées...\n",
      "  - 300/427 images traitées...\n",
      "  - 400/427 images traitées...\n",
      "Chargement de 427 images PNEUMONIA...\n",
      "  - 100/427 images traitées...\n",
      "  - 200/427 images traitées...\n",
      "  - 300/427 images traitées...\n",
      "  - 400/427 images traitées...\n",
      "\n",
      "Dimensions des données:\n",
      "Caractéristiques d'entraînement: (6836, 13)\n",
      "Étiquettes d'entraînement: (6836,)\n",
      "Caractéristiques de validation: (854, 13)\n",
      "Étiquettes de validation: (854,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Extraction des caractéristiques de l'ensemble d'entraînement...\")\n",
    "train_features, train_labels = load_and_extract_features(train_dir)\n",
    "\n",
    "print(\"\\nExtraction des caractéristiques de l'ensemble de validation...\")\n",
    "val_features, val_labels = load_and_extract_features(val_dir)\n",
    "\n",
    "print(\"\\nDimensions des données:\")\n",
    "print(f\"Caractéristiques d'entraînement: {train_features.shape}\")\n",
    "print(f\"Étiquettes d'entraînement: {train_labels.shape}\")\n",
    "print(f\"Caractéristiques de validation: {val_features.shape}\")\n",
    "print(f\"Étiquettes de validation: {val_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416d038",
   "metadata": {},
   "source": [
    "# On feed la data à Random Forest qui va s'entraîner et générer des conclusions, et on sauvegarde les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c403f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier 'numpy_models' créé avec succès.\n",
      "Entraînement du modèle Random Forest...\n",
      "Modèle entraîné en 1.43 secondes\n",
      "\n",
      "Performances sur l'ensemble de validation:\n",
      "Précision (accuracy): 0.8044\n",
      "Précision (precision): 0.8066\n",
      "Rappel (recall): 0.8009\n",
      "Score F1: 0.8038\n",
      "\n",
      "Matrice de confusion:\n",
      "[[345  82]\n",
      " [ 85 342]]\n",
      "\n",
      "Rapport de classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.80      0.81      0.81       427\n",
      "   Pneumonie       0.81      0.80      0.80       427\n",
      "\n",
      "    accuracy                           0.80       854\n",
      "   macro avg       0.80      0.80      0.80       854\n",
      "weighted avg       0.80      0.80      0.80       854\n",
      "\n",
      "Modèle et caractéristiques sauvegardés avec succès dans le dossier 'numpy_models'!\n",
      "Métriques de performance sauvegardées dans le dossier 'numpy_models'!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "numpy_models_dir = 'numpy_models'\n",
    "if not os.path.exists(numpy_models_dir):\n",
    "    os.makedirs(numpy_models_dir)\n",
    "    print(f\"Dossier '{numpy_models_dir}' créé avec succès.\")\n",
    "else:\n",
    "    print(f\"Le dossier '{numpy_models_dir}' existe déjà.\")\n",
    "\n",
    "print(\"Entraînement du modèle Random Forest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=None,   \n",
    "    min_samples_split=2, \n",
    "    random_state=42   \n",
    ")\n",
    "\n",
    "rf_model.fit(train_features, train_labels)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Modèle entraîné en {training_time:.2f} secondes\")\n",
    "\n",
    "val_predictions = rf_model.predict(val_features)\n",
    "\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "precision = precision_score(val_labels, val_predictions)\n",
    "recall = recall_score(val_labels, val_predictions)\n",
    "f1 = f1_score(val_labels, val_predictions)\n",
    "\n",
    "print(\"\\nPerformances sur l'ensemble de validation:\")\n",
    "print(f\"Précision (accuracy): {accuracy:.4f}\")\n",
    "print(f\"Précision (precision): {precision:.4f}\")\n",
    "print(f\"Rappel (recall): {recall:.4f}\")\n",
    "print(f\"Score F1: {f1:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(val_labels, val_predictions)\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(val_labels, val_predictions, \n",
    "                          target_names=['Normal', 'Pneumonie']))\n",
    "\n",
    "\n",
    "with open(os.path.join(numpy_models_dir, 'rf_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "with open(os.path.join(numpy_models_dir, 'train_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_features, f)\n",
    "with open(os.path.join(numpy_models_dir, 'train_labels.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_labels, f)\n",
    "with open(os.path.join(numpy_models_dir, 'val_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_features, f)\n",
    "with open(os.path.join(numpy_models_dir, 'val_labels.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_labels, f)\n",
    "\n",
    "print(f\"Modèle et caractéristiques sauvegardés avec succès dans le dossier '{numpy_models_dir}'!\")\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'confusion_matrix': conf_matrix.tolist()\n",
    "}\n",
    "\n",
    "with open(os.path.join(numpy_models_dir, 'performance_metrics.pkl'), 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "print(f\"Métriques de performance sauvegardées dans le dossier '{numpy_models_dir}'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be5d74",
   "metadata": {},
   "source": [
    "## Conclusion sur le modèle Random Forest\n",
    "\n",
    "Notre modèle de Random Forest, entraîné sur 13 caractéristiques statistiques extraites des radiographies pulmonaires, atteint une précision de 82% dans la détection de pneumonie, avec une meilleure performance pour éviter les faux positifs (précision de 85%) qu'à identifier tous les cas positifs (rappel de 77%). Bien que performant pour une approche basée uniquement sur des statistiques d'image simples, le modèle pourrait être amélioré pour réduire les 23% de cas de pneumonie non détectés, particulièrement critiques dans un contexte médical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pneumonia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
