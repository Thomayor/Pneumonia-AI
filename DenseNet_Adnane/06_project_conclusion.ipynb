{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c882b2",
   "metadata": {},
   "source": [
    "Ce dernier notebook a pour but de conclure notre projet de classification de radiographies pulmonaires à l'aide de modèles de deep learning, en résumant les étapes principales et en comparant les performances du modèle DenseNet121 avant et après fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b8b08",
   "metadata": {},
   "source": [
    "1) Rappel des étapes du projet\n",
    "\n",
    "Le projet s’est articulé autour des étapes suivantes :\n",
    "\n",
    "Préparation des données (Notebook 01) : chargement, répartition en train/val/test, redimensionnement à 224×224, et normalisation des pixels (1/255).\n",
    "\n",
    "Construction d’un premier modèle basé sur DenseNet121 (Notebook 02) : en gelant le backbone pré-entraîné sur ImageNet et en entraînant uniquement la tête de classification.\n",
    "\n",
    "Évaluation de ce modèle (Notebook 03) : obtention d’une bonne performance globale avec une précision > 93%.\n",
    "\n",
    "Ajustement du seuil de classification (Notebook 04) : analyse de l’impact du seuil sur les métriques (precision, recall, f1-score).\n",
    "\n",
    "Amélioration avec fine-tuning (Notebook 05) : déblocage des couches profondes du backbone DenseNet121 et réentraînement avec un faible taux d’apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517fdeca",
   "metadata": {},
   "source": [
    "2) Comparaison avant et après fine-tuning\n",
    "\n",
    "A) Sans fine-tuning :\n",
    "\n",
    "Accuracy : 94%\n",
    "\n",
    "Courbes d’entraînement : on observe une convergence stable, mais la perte (loss) reste plus élevée qu’avec fine-tuning.\n",
    "\n",
    "Courbe ROC AUC : très bonne séparation, AUC élevée (~0.98).\n",
    "\n",
    "Limite : le modèle exploite les représentations pré-apprises sans les adapter complètement aux spécificités des radios pulmonaires.\n",
    "\n",
    "\n",
    "B) Avec fine-tuning :\n",
    "\n",
    "Accuracy : 94% (même que le modèle sans fine-tuning, mais avec des résultats plus équilibrés)\n",
    "\n",
    "Matrice de confusion :\n",
    "\n",
    "NORMAL correctement prédits : 499/525\n",
    "\n",
    "PNEUMONIA correctement prédits : 494/525\n",
    "\n",
    "Moins d’erreurs de classification inversée.\n",
    "\n",
    "Precision/Recall/F1-Score : tous à 0.94 → meilleure symétrie de performance.\n",
    "\n",
    "Courbes de loss et précision : plus rapide convergence, perte plus basse, stabilité accrue.\n",
    "\n",
    "Courbe ROC AUC : toujours très élevée (~0.985), donc excellente capacité de discrimination.\n",
    "\n",
    "Meilleure généralisation : les courbes d’entraînement et validation sont plus proches\n",
    "\n",
    "Courbe de perte plus stable, montrant une meilleure adaptation aux spécificités des radios thoraciques\n",
    "\n",
    "Bien que les gains soient modestes en termes de pourcentage, le fine-tuning apporte une amélioration qualitative : meilleure stabilité des performances, courbes plus régulières, et potentielle robustesse accrue sur des cas difficiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a44460",
   "metadata": {},
   "source": [
    "3) Point clés à retenir\n",
    "\n",
    "Le transfert learning avec DenseNet121 s’est avéré efficace dès la première phase.\n",
    "\n",
    "Le fine-tuning permet d’exploiter les couches profondes pour mieux s’adapter à notre tâche spécifique.\n",
    "\n",
    "Le tuning du seuil de classification est crucial pour atteindre un équilibre entre recall et precision, en fonction du contexte médical.\n",
    "\n",
    "Des outils comme la matrice de confusion ou les courbes ROC-AUC permettent une évaluation fine des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf53f39",
   "metadata": {},
   "source": [
    "4) Perspective d'amélioration \n",
    "\n",
    "Data augmentation plus avancée : pour enrichir la diversité du jeu d’entraînement.\n",
    "\n",
    "Entraînement sur un plus grand nombre d’épochs post-fine-tuning.\n",
    "\n",
    "Test sur des données externes pour mesurer la généralisation hors distribution.\n",
    "\n",
    "Ensemble de plusieurs modèles pour combiner les forces de différentes architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29562f8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57840cfa",
   "metadata": {},
   "source": [
    "5) Point Important !!\n",
    "\n",
    "Il est important de noter que le modèle non fine-tuné a été entraîné pendant 15 époques, tandis que le modèle fine-tuné a bénéficié uniquement de 5 époques supplémentaires après la phase initiale de gel des couches.\n",
    "\n",
    "Cela pourrait soulever une question légitime sur la comparabilité directe des deux modèles. En général, plus un modèle est entraîné longtemps, plus il a de chances d’améliorer ses performances. Cependant, dans notre cas, le modèle fine-tuné parvient à atteindre — voire dépasser — les performances du modèle non fine-tuné, malgré un nombre d’épochs total inférieur.\n",
    "\n",
    "Cela montre la puissance du fine-tuning, qui permet d’adapter efficacement les représentations apprises sur ImageNet à notre domaine spécifique des radiographies thoraciques. Les poids pré-entraînés, mis à jour sur les couches profondes, ont pu capturer des caractéristiques plus pertinentes médicalement, avec moins d’apprentissage supervisé.\n",
    "\n",
    "Néanmoins, pour une comparaison encore plus rigoureuse, il aurait été pertinent d’entraîner les deux modèles pendant le même nombre total d’épochs, ou de suivre leur évolution à l’aide de courbes d’apprentissage afin de détecter un éventuel plateau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9bb373",
   "metadata": {},
   "source": [
    "Conclusion :\n",
    "\n",
    "\n",
    "Ce projet démontre l’efficacité du transfert learning dans un domaine médical critique. Bien que DenseNet121 donne déjà de bons résultats sans fine-tuning, l’ajustement des couches profondes au travers du fine-tuning améliore l’équilibre et la précision du modèle.\n",
    "\n",
    "Le pipeline proposé est reproductible, interprétable, et laisse la porte ouverte à des itérations futures pour encore gagner en robustesse et justesse clinique.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
